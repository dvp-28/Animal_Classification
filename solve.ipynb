{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe42f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb9533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1944 images belonging to 15 classes.\n",
      "Found 1819 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load & Process Data\n",
    "\n",
    "train_path = \"E:\\\\Unified Mentor\\\\Projects\\\\Animal Classification\\\\dataset\\\\Train\"\n",
    "val_path = \"E:\\\\Unified Mentor\\\\Projects\\\\Animal Classification\\\\dataset\\\\Validation\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path,\n",
    "                                                    target_size=(224,224),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(val_path,\n",
    "                                                target_size=(224,224),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d08b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# CNN Model\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32,(3,3), activation='relu', input_shape=(224,224,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(64,(3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(128,(3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(15, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd858bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 3s/step - accuracy: 0.0776 - loss: 2.7548 - val_accuracy: 0.1715 - val_loss: 2.5905\n",
      "Epoch 2/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.1542 - loss: 2.5923 - val_accuracy: 0.3035 - val_loss: 2.3842\n",
      "Epoch 3/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2s/step - accuracy: 0.2258 - loss: 2.4368 - val_accuracy: 0.3881 - val_loss: 2.1320\n",
      "Epoch 4/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.2653 - loss: 2.3013 - val_accuracy: 0.4810 - val_loss: 1.9588\n",
      "Epoch 5/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.3261 - loss: 2.1361 - val_accuracy: 0.5767 - val_loss: 1.9131\n",
      "Epoch 6/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.3760 - loss: 2.0244 - val_accuracy: 0.6097 - val_loss: 1.6185\n",
      "Epoch 7/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 2s/step - accuracy: 0.4169 - loss: 1.8746 - val_accuracy: 0.6877 - val_loss: 1.5027\n",
      "Epoch 8/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - accuracy: 0.4521 - loss: 1.7733 - val_accuracy: 0.7405 - val_loss: 1.3303\n",
      "Epoch 9/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 2s/step - accuracy: 0.4885 - loss: 1.6365 - val_accuracy: 0.7774 - val_loss: 1.1900\n",
      "Epoch 10/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.5332 - loss: 1.5118 - val_accuracy: 0.8252 - val_loss: 1.1170\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262fe573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 418ms/step - accuracy: 0.8382 - loss: 1.1129\n",
      "Validation Accuracy: 82.52%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82343d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step\n",
      "Predicted Animal: Cat\n"
     ]
    }
   ],
   "source": [
    "# Test the MOdel\n",
    "\n",
    "img_path = 'E:\\\\Unified Mentor\\\\Projects\\\\Animal Classification\\\\dataset\\\\1.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_tensor = image.img_to_array(img) / 255.0\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "prediction = model.predict(img_tensor)\n",
    "predicted_class = list(train_generator.class_indices.keys())[np.argmax(prediction)]\n",
    "\n",
    "print(\"Predicted Animal:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
